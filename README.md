# le_grand_scrape :fr: :space_invader:

### TODO for now:

- [ ] get `selenium` + python (or anything else) to work on a few contributions

- [ ] write basic tests for scraper (to ensure we don't spend days scraping nothing when we deploy scraper)

- [ ] deploy scrapper on `AWS` or `GCP` (get an estimate of final size of file so that we don't crash the machine)

Ideally we should perhaps scrape as follows:
- *scrape* 5000 observations via the virtual machine
- *test* that scrape went well for those 5000 obs
- *zip* it (or not) and *send* it to GoogleDrive (so as to save space on the virtual machine)
The outcome would be a folder containing ~ 50,000 contrib * 4 themes / 5,000 obs = 40 zipped files)

Aussi j'ai créé un compte pour le site du Grand Debat, si besoin:
mail: `v.viers@lse.ac.uk`
mdp: `elGranDebato`
